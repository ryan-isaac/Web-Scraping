# "Trip Advisor" Web Scraping Project

## Introduction
Some websites that have a lot of options, information, many pages of suggestions and products might be hard to navigate through and can be time consuming.  However, filtering and sorting features can give you a better way to view these options, but, what if the website has a lot of options that even after filtering you still have thousands of options to choose from.  Instead of spending hours looking at endless pages of options, what if there is a way to see everything based on your own set of filters. Web Scraping is an efficient way to see contents of websites with your own settings.  Applications of web scraping can go beyond personal use of course. Companies can use the data in other websites to gain insights about markets, products, reviews, trends, etc...

## Project Objective
Although the use cases of web scraping are many, this project demonstrates how web scraping is used for a specific website to collect specific data, store them in in a data frame and then analyze them to get insights. The website selected for this project is Trip Advisor.  It is an open website that anyone can access.  

## Approach
The web scraping tool used in this case is Selenium, which allows collecting data from the html script of the website while avoiding being blocked by the website's server. The way it works is that Selenium opens a webpage where it navigates through it using specific instructions on what to click on, when to click on it, and where to scroll to, all done automatically.  Selenium is used to mimic the human behavior in accessing websites and allows to overcome some restrictions that the website server might have on robots that could lead to DDoS attacks.




* Please go through the Jupyter notebook file for full code and notes on each step. There is also a PowerPoint presentation that you can refer to.

